概述
=================
  在高处，每一个Spark程序由一个运行用户主方法的驱动程序和运行在集群上的各种并行操作组成。Spark提供的主要抽象是RDD,RDD是一个元素分布在集群节点中可以执行并行计算的数据集合。RDD的创建`
可以通过Hadoop文件系统的一个文件开始创建（或者其他Hadoop支持的文件系统），或者一个驱动程序中的Scala集合，创建后可以基于已有的RDD进行变换，用户也可以让Spark持久化RDD到内存，通过并行运算可以允许
数据高效的使用，最后一点是RDD自动的覆盖已经错误的节点。

